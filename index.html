<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Igor Molybog</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="CV.pdf">CV</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=aJUg17UAAAAJ&hl=en">Publications</a></div>
<div class="menu-item"><a href="https://github.com/igormolybogFB">GitHub</a></div>
<div class="menu-category">Teaching</div>
<div class="menu-item"><a href="ee650_fall2023.html">EE650</a></div>
<div class="menu-item"><a href="ieor169.html">IEOR169</a></div>
<div class="menu-item"><a href="ieor240.html">IEOR240</a></div>
<div class="menu-item"><a href="https://calendar.app.google/mLp9CvS96utpEjDK6">Book&nbsp;an&nbsp;Appointment</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Igor Molybog</h1>
</div>
<table class="imgtable"><tr><td>
<img src="myport.jpg" alt="" width="260px" height="260px" />&nbsp;</td>
<td align="left"><p><u>Igor Molybog</u> <br />  
Researcher in the domains of Numerical Optimization and Machine Learning <br />  
Email: <i>igormolybog AT gmail.com</i> <br />
</p>
</td></tr></table>
<h2>About me</h2>
<p>I am a researcher working on the training of Generative Artificial Intelligence. My research 
interests cover the area of computational techniques for learning from data
that are highly scalable with the availability of the compute. More specifically, I am working on optimizers 
and model architecture scaling schemes that would allow predictable 
and efficient training of Transformer models containing hundreds of billions of parameters.
</p>
<p>In 2022, I graduated with a Ph.D. from the group of <a href="http://www.ieor.berkeley.edu/~lavaei/" target=&ldquo;blank&rdquo;>Professor Javad Lavaei</a> at the Department of 
Industrial Engineering and Operations Research at University of California, Berkeley, where I worked
on problems of algorithmic analysis and optimal control of complex safety-critical systems, such as power systems, 
transportation and telecommunication networks, AI recommendation and navigation systems, robotic systems, and others.
My research spanned the theory of non-convex and conic optimization, stochastic control, machine learning,
and computational and sampling complexity of learning algorithms. I designed data processing algorithms 
that are robust to noise and highly scalable with the amount of available computational resources.
</p>
<h2>News</h2>
<ul>
<li><p>October 2023: I am chairing session WA67 &ldquo;Challanges in the Large-scale Model Training&rdquo; at INFORMS Annual Meeting 2023!
</p>
</li>
<li><p>October 2023: I have presented a talk on the Large Language Modeling practice at the CS Department seminar of UH Manoa: <a href="https://drive.google.com/file/d/19H5-6PspYAjf4sgSefM0HrnjgRgj1060/view?usp=sharing" target=&ldquo;blank&rdquo;>recording</a>, <a href="https://drive.google.com/file/d/1X4KBCU0DiHtQ0aJrLlYKe8509hZFilcY/view?usp=sharing" target=&ldquo;blank&rdquo;>slides</a>
</p>
</li>
<li><p>September 2023: A new paper on extending the context length of a trained RoPE transformer: <a href="https://arxiv.org/pdf/2309.16039.pdf" target=&ldquo;blank&rdquo;>Effective Long-Context Scaling of Foundation Models</a>
</p>
</li>
<li><p>July 2023: Our paper <a href="https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/" target=&ldquo;blank&rdquo;>Llama 2: Open Foundation and Fine-Tuned Chat Models</a> landed with a splash, <a href="https://news.ycombinator.com/item?id=36774627" target=&ldquo;blank&rdquo;>making it to the top</a> of hackernews.
</p>
</li>
<li><p>May 2023: I will present the paper <a href="https://arxiv.org/abs/2304.09871" target=&ldquo;blank&rdquo;>A Theory on Adam Instability in Large-Scale Machine Learning</a> at the FAIR &lt;&gt; GenAI Workshop. <a href="https://docs.google.com/presentation/d/1MAcgmCgx5b6zf9So42Bh-af9HvOGdBkUrJHKmJPp4IU/edit?usp=sharing" target=&ldquo;blank&rdquo;>slides</a>
</p>
</li>
<li><p>April 2023: Our paper <a href="https://people.eecs.berkeley.edu/~sojoudi/Saddle_2023_1.pdf" target=&ldquo;blank&rdquo;>Over-parametrization via Lifting for Low-rank Matrix Sensing: Conversion of Spurious Solutions to Strict Saddle Points</a> got accepted at the 2023 International Conference on Machine Learning (ICML).
</p>
</li>
<li><p>March 2023: New paper <a href="https://arxiv.org/abs/2304.09871" target=&ldquo;blank&rdquo;>A Theory on Adam Instability in Large-Scale Machine Learning</a> is accessible online.
</p>
</li>
<li><p>January 2023: New paper <a href="https://people.eecs.berkeley.edu/~sojoudi/Saddle_2023_1.pdf" target=&ldquo;blank&rdquo;>Over-parametrization via Lifting for Low-rank Matrix Sensing: Conversion of Spurious Solutions to Strict Saddle Points</a> is accessible online.
</p>
</li>
<li><p>October 2022: I am invited to organize a session &ldquo;Large-scale smooth optimization for Generative AI&rdquo; at the <a href="https://meetings.informs.org/wordpress/phoenix2023/" target=&ldquo;blank&rdquo;>INFORMS Annual Meeting 2023</a>.
</p>
</li>
<li><p>June 2022: I am joining <a href="https://ai.facebook.com/" target=&ldquo;blank&rdquo;>Meta AI (FAIR)</a> as a Research Scientist specializing on large-scale optimization.
</p>
</li>
<li><p>May 2022: I defended my thesis and graduated with a Ph.D. in Engineering! 
</p>
</li>
<li><p>April 2022: My Thesis <a href="https://escholarship.org/content/qt9jx9w0mh/qt9jx9w0mh.pdf" target=&ldquo;blank&rdquo;>The complexity of non-convex and conic optimization problems in data science applications</a> is available online.
</p>
</li>
<li><p>February 2022: I will give a talk at the Department of Electrical and Computer Engineeting of University of Hawai'i at Manoa. <a href="https://docs.google.com/presentation/d/1fPviatr3hesi-hL6GkUffwp4uvJizSQSZ2fuSELAus8/edit?usp=sharing" target=&ldquo;blank&rdquo;>slides</a>
</p>
</li>
<li><p>December 2021: I will give a talk &ldquo;Computation-information complexity trade-off in Tensor PCA&rdquo; Random Matrices and Random Landscapes seminar at Mathematical Sciences Research Institute, Berkeley, CA. (<a href="Rand_Mat___Land_Project_Presentation_Dec_2021.pdf" target=&ldquo;blank&rdquo;>slides</a>)
</p>
</li>
<li><p>November 2021: I will give a talk &ldquo;Topological complexity of polynomials&rdquo; at the Control and Optimization seminar, IEOR Department at University of California, Berkeley. (<a href="Presentation_Spin_Glass_November_2021.pdf" target=&ldquo;blank&rdquo;>slides</a>)
</p>
</li>
<li><p>September 2021: I am organising session &ldquo;Reaching Global Optimum in Non-Convex Optimization Problems&rdquo; at the INFORMS Annual Meeting 2021.
</p>
</li>
<li><p>July 2021: I will present the paper <a href="https://arxiv.org/pdf/2006.00453" target=&ldquo;blank&rdquo;>When Does MAML Objective Have Benign Landscape?</a> on the 2021 IEEE Conference on Control Technology and Applications (CCTA).
</p>
</li>
<li><p>May 2021: I will present the paper <a href="https://people.eecs.berkeley.edu/~sojoudi/SRIP_21.pdf" target=&ldquo;blank&rdquo;>No spurious solutions in non-convex matrix sensing: Structure compensates for isometry</a> on the 2021 American Control Conference (ACC).
</p>
</li>
<li><p>December 2020: Our paper <a href="https://people.eecs.berkeley.edu/~sojoudi/KSP_2019_1.pdf" target=&ldquo;blank&rdquo;>Role of sparsity and structure in the optimization landscape of non-convex matrix sensing</a>  got accepted for publication in <a href="https://www.springer.com/journal/10107" target=&ldquo;blank&rdquo;>Mathematical Programming</a>.
</p>
</li>
<li><p>September 2020: Our paper <a href="https://www.jmlr.org/papers/volume21/18-881/18-881.pdf" target=&ldquo;blank&rdquo;>Conic Optimization for Quadratic Regression Under Sparse Noise</a> got accepted for publication in the <a href="https://www.jmlr.org/" target=&ldquo;blank&rdquo;>Journal of Machine Learning Research</a>.
</p>
</li>
<li><p>June 2020: Our new paper <a href="https://lavaei.ieor.berkeley.edu/Meta_2020_1.pdf" target=&ldquo;blank&rdquo;>Global convergence of MAML for LQR</a> is accessible online.
</p>
</li>
<li><p>August 2019: I gave a talk &ldquo;Frontiers of Deep Learning: overview of Simon's Institute summer workshops&rdquo; at the Control and Optimization seminar, IEOR Department at University of California, Berkeley. (<a href="simonsTalk.pdf" target=&ldquo;blank&rdquo;>slides</a>)
</p>
</li>
<li><p>July 2019: The paper <a href="http://www.ieor.berkeley.edu/~lavaei/linear-SE_2019_2.pdf" target=&ldquo;blank&rdquo;>Towards Robust and Scalable Power System State Estimation</a> to appear in Proc. 58th  IEEE Conference on Decision and Control
</p>
</li>
<li><p>May 2019: New paper on non-convex learning: <a href="http://www.ieor.berkeley.edu/~lavaei/SRIP_2019_1.pdf" target=&ldquo;blank&rdquo;>No Spurious Solutions in Non-convex Matrix Sensing: Structure Compensates for Isometry</a>
</p>
</li>
<li><p>January 2019: New paper on data analytics: <a href="http://www.ieor.berkeley.edu/~lavaei/Conic_RQR_2018.pdf" target=&ldquo;blank&rdquo;>Conic Optimization for Robust Quadratic Regression</a>
</p>
</li>
<li><p>December 2018: Our paper <a href="http://lavaei.ieor.berkeley.edu/Sampling_SDP_2018.pdf" target=&ldquo;blank&rdquo;>On Sampling Complexity of the Semidefinite Affine Rank Feasibility Problem</a> has been designated for oral presentation on <a href="https://aaai.org/Conferences/AAAI-19/" target=&ldquo;blank&rdquo;>Thirty-Third AAAI Conference on Artificial Intelligence</a>
</p>
</li>
<li><p>November 2018: I will give a talk &ldquo;Conic Optimization For Robust Quadratic Regression&rdquo; at the <a href="https://cdc2018.ieeecss.org/" target=&ldquo;blank&rdquo;>57th IEEE Conference on Decision and Control</a>
</p>
</li>
<li><p>October 2018: Our paper <a href="http://www.ieor.berkeley.edu/~lavaei/Sampling_SDP_2018.pdf" target=&ldquo;blank&rdquo;>On Sampling Complexity of the Semidefinite Affine Rank Feasibility Problem</a> was accepted on <a href="https://aaai.org/Conferences/AAAI-19/" target=&ldquo;blank&rdquo;>Thirty-Third AAAI Conference on Artificial Intelligence</a>
</p>
</li>
<li><p>September 2018: I successfully passed Doctoral Qualifying Examination.
</p>
</li>
<li><p>September 2018: I gave a talk &ldquo;Geometry of SDP relaxations for rank constrained problems&rdquo; at the Power Systems Seminar for IEOR Department at University of California, Berkeley.
</p>
</li>
<li><p>September 2018: New paper on SDP relaxations of rank-constrained problems: <a href="http://lavaei.ieor.berkeley.edu/Sampling_SDP_2018.pdf" target=&ldquo;blank&rdquo;>On Sampling Complexity of the Semidefinite Affine Rank Feasibility Problem</a>.
</p>
</li>
<li><p>July 2018: Our paper <a href="http://www.ieor.berkeley.edu/~lavaei/regression_2018_1.pdf" target=&ldquo;blank&rdquo;>Conic Optimization for Robust Quadratic Regression: Deterministic Bounds and Statistical Analysis</a> to appear in IEEE Conference on Decision and Control, 2018.
</p>
</li>
<li><p>July 2018: I will give a talk on &ldquo;Conic Optimization For Robust State Estimation: Deterministic Bounds And Statistical Analysis&rdquo; at <a href="http://meetings2.informs.org/wordpress/phoenix2018/" target=&ldquo;blank&rdquo;>INFORMS Annual Meeting</a>
</p>
</li>
<li><p>May 2018: I successfully passed Ph.D. Preliminary Exam.
</p>
</li>
<li><p>April 2018: I gave a talk on &ldquo;Conic Relaxations for State Estimation under Sparse Noise&rdquo; at the Power Systems Seminar for IEOR Department at University of California, Berkeley.
</p>
</li>
<li><p>March 2018: New paper on robust nonlinear regression for bad data detection: <a href="http://www.ieor.berkeley.edu/~lavaei/regression_2018_1.pdf" target=&ldquo;blank&rdquo;>Conic Optimization for Robust Quadratic Regression: Deterministic Bounds and Statistical Analysis</a>.
</p>
</li>
<li><p>August 2017: I joined the department of <a href="http://www.ieor.berkeley.edu" target=&ldquo;blank&rdquo;>Industrial Engineering and Operations Research</a> at <a href="http://www.berkeley.edu" target=&ldquo;blank&rdquo;>University of California, Berkeley</a> as a M.Sc/PhD Scholar.
</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
